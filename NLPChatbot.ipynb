{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Build a chatbot pipeline using transformers library"
      ],
      "metadata": {
        "id": "KwmtJxciVbcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First step is to import the Transformers library\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W3fcVDFVl6r",
        "outputId": "3ab4589d-fb37-4701-e547-1cfc9986c009"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import code that supresses message warnings\n",
        "from transformers.utils import logging\n",
        "logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "jTFYuI4XV9bT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pipeline\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "Gd5ydj9wWQ6m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After importing the pipeline, yo define t.\n",
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/blenderbot-400M-distill\")\n",
        "\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_message = input(\"You: \")\n",
        "\n",
        "    # Check if the user wants to exit\n",
        "    if user_message.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "        break\n",
        "\n",
        "    # Generate bot response\n",
        "    inputs = tokenizer(user_message, return_tensors=\"pt\")\n",
        "    reply_ids = model.generate(**inputs)\n",
        "    bot_message = tokenizer.batch_decode(reply_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    # Print bot response\n",
        "    print(\"Bot:\", bot_message)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoYfv0HWWpIC",
        "outputId": "39c73e8d-2d4c-4929-fdb0-e13477cf0ff9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: What are some of the tips you can give me when applying for a data analyst role?\n",
            "Bot:  Make sure you have a good resume, and be prepared to answer questions that you may not be able to answer.\n",
            "You: What else can you recommend?\n",
            "Bot:  I can't really think of anything else at the moment, but I'm sure I can come up with something.\n",
            "You: Cool\n",
            "Bot:  Do you have any pets? I have a dog and a cat. I love them so much.\n",
            "You: bye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_message = \"\"\"\n",
        "What are some fun activities I can do in the winter?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "wdP44Lf1Yp8T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You already have these imports\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Instead of importing a non-existent module, use the loaded model directly\n",
        "# Use the tokenizer and model you loaded earlier for conversational tasks.\n",
        "\n",
        "inputs = tokenizer(user_message, return_tensors=\"pt\")\n",
        "reply_ids = model.generate(**inputs)\n",
        "bot_message = tokenizer.batch_decode(reply_ids, skip_special_tokens=True)[0]\n",
        "print(bot_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XvlUihebCwT",
        "outputId": "6daec98d-7927-4775-a53e-a85d303e1925"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I like snowboarding and skiing.  What do you like to do in winter?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_message=\"What else do you recommend?\""
      ],
      "metadata": {
        "id": "SSjntZ-QbzG0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bot_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-0HbxoxcOKa",
        "outputId": "fe9354b3-4e73-4ca1-9707-e668ce6628fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I like snowboarding and skiing.  What do you like to do in winter?\n"
          ]
        }
      ]
    }
  ]
}